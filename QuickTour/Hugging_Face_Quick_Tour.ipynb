{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugging Face Quick Tour.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ryzge5XPO_vV",
        "_pSU-NPIO8FH",
        "8dDyuQG9PUEH",
        "xz1y_-raNS3F",
        "aqRGBtD-SM1A",
        "SqOQD8bbS2YO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryzge5XPO_vV"
      },
      "source": [
        "# 安装transformers库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82p-gBywPDgR",
        "outputId": "231409e9-eb74-440d-9a4c-8b9eb79b13f1"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 39.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pSU-NPIO8FH"
      },
      "source": [
        "# 使用流水线进行文本情感判断"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDyuQG9PUEH"
      },
      "source": [
        "## 正向情感示例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay1J2al-PvBP"
      },
      "source": [
        "第二行代码下载并缓存了流水线使用的预训练模型，而第三行代码则在给定的文本上进行了评估。这里的答案“正面” (positive) 具有 99 的置信度。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuzRwOJvNM8r",
        "outputId": "fb034775-26ba-4065-fa3a-1be9b49df7c4"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 使用情绪分析流水线\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "classifier('We are very happy to introduce pipeline to the transformers repository.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9996980428695679}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz1y_-raNS3F"
      },
      "source": [
        "## 负向情感示例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THyhDPobPcLc",
        "outputId": "c1010c2a-2aa3-4c3c-c6be-ea3909586042"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 使用情绪分析流水线\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "classifier('damn, how the weather is today!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9843284487724304}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqRGBtD-SM1A"
      },
      "source": [
        "## 中文尝试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UnCZXvkSOK5",
        "outputId": "be55ae24-67ae-4f9f-9264-b4db1bf3e9f1"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 使用情绪分析流水线\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "a = classifier('今天的天气真好啊！')\n",
        "print(a)\n",
        "b = classifier('今天的天气不太好，郁闷啊！')\n",
        "print(b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.7827630639076233}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.7204760909080505}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqOQD8bbS2YO"
      },
      "source": [
        "# 使用流水线从给定文本问题中抽取答案"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lvvEnXnXcHr"
      },
      "source": [
        "英文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYx56SBkS8r4",
        "outputId": "d76aee04-a16d-458b-eb18-31638c3b2f80"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 使用问答流水线\n",
        "question_answerer = pipeline('question-answering')\n",
        "question_answerer({\n",
        "    'question': 'What is the name of the repository ?',\n",
        "    'context': 'Pipeline has been included in the huggingface/transformers repository'\n",
        "    })"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'huggingface/transformers',\n",
              " 'end': 58,\n",
              " 'score': 0.30970120429992676,\n",
              " 'start': 34}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNp8nnYcXgUc"
      },
      "source": [
        "中文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8Joe_nZTMYy",
        "outputId": "2fbd0824-2122-48a5-fab9-8782430ab077"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 使用问答流水线\n",
        "question_answerer = pipeline('question-answering')\n",
        "question_answerer({\n",
        "    'question': '勒克莱尔在哪里退赛了',\n",
        "    'context': '勒克莱尔在匈牙利大奖赛中退赛'\n",
        "    })"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '中退赛', 'end': 14, 'score': 0.009904472157359123, 'start': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XfB4hW7duR2"
      },
      "source": [
        "# 使用预训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tNM6kYgdwAG",
        "outputId": "62042d38-dbe6-4d3f-9965-5027615f9aa4"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
        "# print(\"inputs：\", inputs) \n",
        "# >>> {'input_ids': tensor([[ 101, 7592, 2088,  999,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
        "\n",
        "outputs1 = model(**inputs)\n",
        "# equals to\n",
        "outputs2 = model(inputs['input_ids']) # 为什么token_type_ids和attention_mask没有用到，可能还需要根据之后的教程进一步学习了\n",
        "\n",
        "print(outputs1['last_hidden_state'] == outputs2['last_hidden_state'])\n",
        "\n",
        "print(\"outputs1['last_hidden_state'].shape:\", outputs1['last_hidden_state'].shape)\n",
        "print(\"outputs1['pooler_output'].shape:\", outputs1['pooler_output'].shape)\n",
        "\n",
        "# BaseModelOutputWithPoolingAndCrossAttentions对象\n",
        "# print(outputs) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[[True, True, True,  ..., True, True, True],\n",
            "         [True, True, True,  ..., True, True, True],\n",
            "         [True, True, True,  ..., True, True, True],\n",
            "         [True, True, True,  ..., True, True, True],\n",
            "         [True, True, True,  ..., True, True, True]]])\n",
            "outputs1['last_hidden_state'].shape: torch.Size([1, 5, 768])\n",
            "outputs1['pooler_output'].shape: torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}